# -*- coding: utf-8 -*-
"""quora scrap.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ktf_O7D7GU8XT0CB9LLjejBwABT1qyER
"""

#requirement
# !pip install selenium

# !pip install webdriver-manager

from bs4 import BeautifulSoup
import requests
import time
import re

def get_quora_posts(url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.90 Safari/537.36"
    }

    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        print(f"Erreur HTTP: {response.status_code}")
        return []

    soup = BeautifulSoup(response.text, 'html.parser')

    # Updated CSS selector to target question links within the topic feed
    posts = soup.select('a.q-box.qu-cursor--pointer.qu-hover--textDecoration--underline')

    data = []
    for post in posts:
        try:
            title = post.text.strip()
            #https://www.quora.com
            # Extract the question URL from the link
            question_url = "https://relationsetamour.quora.com/15-v%C3%A9rit%C3%A9s-g%C3%AAnantes-que-les-gens-apprennent-trop-tard-sur-la-vie" + post['href']

            # Fetch the question page to get comments and views
            question_response = requests.get(question_url, headers=headers)
            question_soup = BeautifulSoup(question_response.text, 'html.parser')

            # Updated selectors for comments and views (more robust)
            comments_element = question_soup.find('span', class_='q-text', string=lambda text: 'comment' in text)
            views_element = question_soup.find('span', class_='q-text', string=lambda text: 'view' in text)

            comments = int(comments_element.text.split()[0]) if comments_element else 0
            views = int(views_element.text.split()[0].replace('k', '000')) if views_element else 0

            data.append({
                'title': title,
                'comments': comments,
                'views': views,
            })
            # Updated selectors (example, adjust as needed)
            comments_element = question_soup.select_one('span.q-text:contains("comment")')
            views_element = question_soup.select_one('span.q-text:contains("view")')

            # Extract numbers using regular expressions (more robust)
            comments = int(re.search(r'\d+', comments_element.text).group(0)) if comments_element else 0
            views = int(re.search(r'\d+', views_element.text).group(0)) if views_element else 0

            # Debug printing
            print(f"Title: {title}, Comments: {comments}, Views: {views}")

            data.append({
                'title': title,
                'comments': comments,
                'views': views,
            })

            # Introduce a small delay to avoid overwhelming Quora
            time.sleep(1)

        except Exception as e:
            print(f"Erreur lors de l'extraction d'un élément : {e}")
            continue

    return data
def main():
    url = "https://relationsetamour.quora.com/15-v%C3%A9rit%C3%A9s-g%C3%AAnantes-que-les-gens-apprennent-trop-tard-sur-la-vie"
    data = get_quora_posts(url)

    # Sort the data by views and then by comments
    sorted_data = sorted(data, key=lambda x: (x['views'], x['comments']), reverse=True)

    # Display all results
    print("All extracted posts (sorted by views and comments):")
    for post in sorted_data:
        print(f"Title: {post['title']}")
        print(f"Comments: {post['comments']}, Views: {post['views']}")
        print("-" * 40)

if __name__ == "__main__":
    main()
# ... (rest of the code remains the same)

"""code avec stockage dans un fichier .json"""

from bs4 import BeautifulSoup
import requests
import time
import re
import json

def get_quora_posts(url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.90 Safari/537.36"
    }

    # Récupérer la page
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        print(f"Erreur HTTP: {response.status_code}")
        return []

    # Parser le contenu de la page
    soup = BeautifulSoup(response.text, 'html.parser')

    # Sélecteur CSS pour les posts (à adapter selon la structure de Quora)
    posts = soup.select('a.q-box.qu-cursor--pointer.qu-hover--textDecoration--underline')

    data = []
    for post in posts:
        try:
            # Titre du post
            title = post.text.strip()

            # URL complète de la question
            question_url = "https://www.quora.com" + post['href']

            # Récupérer la page de la question
            question_response = requests.get(question_url, headers=headers)
            question_soup = BeautifulSoup(question_response.text, 'html.parser')

            # Extraire les commentaires et les vues (à adapter selon la structure de Quora)
            comments_element = question_soup.find('div', class_='q-text', text=re.compile(r'\d+\s*comment'))
            views_element = question_soup.find('div', class_='q-text', text=re.compile(r'\d+\s*view'))

            # Extraire les nombres avec des expressions régulières
            comments = int(re.search(r'\d+', comments_element.text).group()) if comments_element else 0
            views = int(re.search(r'\d+', views_element.text).group()) if views_element else 0

            # Ajouter les données à la liste
            data.append({
                'title': title,
                'comments': comments,
                'views': views,
                'url': question_url  # Ajout de l'URL pour référence
            })

            # Debug printing
            print(f"Title: {title}, Comments: {comments}, Views: {views}, URL: {question_url}")

            # Délai pour éviter de surcharger le serveur
            time.sleep(1)

        except Exception as e:
            print(f"Erreur lors de l'extraction d'un élément : {e}")
            continue

    return data

def main():
    # URL de la page Quora à scraper
    url = "https://www.quora.com/topic/Relationships-and-Dating"
    data = get_quora_posts(url)

    # Trier les données par vues et commentaires
    sorted_data = sorted(data, key=lambda x: (x['views'], x['comments']), reverse=True)

    # Afficher les résultats
    print("All extracted posts (sorted by views and comments):")
    for post in sorted_data:
        print(f"Title: {post['title']}")
        print(f"Comments: {post['comments']}, Views: {post['views']}")
        print(f"URL: {post['url']}")
        print("-" * 40)

    # Sauvegarder les données dans un fichier JSON
    with open('quora_posts.json', 'w', encoding='utf-8') as json_file:
        json.dump(sorted_data, json_file, ensure_ascii=False, indent=4)

    print("Data saved to quora_posts.json")

if __name__ == "__main__":
    main()

# !pip install beautifulsoup4